getwd()
load(url("http://bit.ly/dasi_gss_data"))
names(GSS)
names(dasi_gss_data)
names(gss)
str(income06)
str(gss$income06)
summary(gss$income06)
summary(gss$degreee)
summary(gss$degree)
hist(gss$income06)
hist(10,gss$income06)
barplot(gss$income06)
?barplot
?dim
dim(gss)
barplot(table(gss$income06))
?barplot
barplot(table(gss$income06),xlab="income")
plot(gss$income06,gss$degree)
plot(gss$income06,gss$degree,type="l")
plot(gss$degree,gss$income06,type="l")
gss$income06
summary(gss$income06)
barplot(table(gss$income06))
barplot(table(gss$degree))
summary(gss$degree)
?subset
gss
c(gss$income06,gss$degree)
table(gss$degree,gss$income06)
dataset=cbind(gss$degree,gss$income06)
dataset
tail(dataset)
tail(dataset,30)
pf(21,3,791,lower.tail=FALSE)
4.259048e-13
sqrt(3.4**2/18+2.7**2/18)
pt(0.5,df=17,lower.tail=FALSE)
download.file(url = "http://bit.ly/dasi_project_template", destfile = "dasi_project_template.Rmd")
sqrt(0.4/0.07)
sqrt(0.2/0.07)
sqrt(0.2/0.4)
(0.2/0.075)^2
(0.2/0.075)
sqrt(13)
install.packages("KernSmooth")
library(KernSmooth)
load("/Users/haoranwang/Desktop/网络课程笔记/Data Science Track/R programming/Programming exercises-swirl/Untitled.RData")
myData
int(2)
numeric(2)
i=6
numeric(i)
class(i)
? ave
ave(1:3)
ave(1;4)
ave(1:4)
train=read.csv("train.csv")
names(train)
train[,1][1]
train[,1][2]
train[,1][0]
glm=glm(Happy~.,data=train,family=binomial)
summary(glm)
glm2=glm(Happy~HouseholdStatus+Income+EducationLevel+Q122769+Q120194+Q120014+Q119334+Q119650+Q118237+Q115777+Q115611+Q115899+Q114386+Q113992+Q110740+Q107869+Q106388+Q106389+Q102674+Q102687+Q102289+Q102089+Q101162+Q100680+Q99716+Q98869)
glm2=glm(Happy~HouseholdStatus+Income+EducationLevel+Q122769+Q120194+Q120014+Q119334+Q119650+Q118237+Q115777+Q115611+Q115899+Q114386+Q113992+Q110740+Q107869+Q106388+Q106389+Q102674+Q102687+Q102289+Q102089+Q101162+Q100680+Q99716+Q98869,data=train,family=binomial)
summary(glm2)
predict2=predict(glm2,newdata=data,type="response")
predict2=predict(glm2,newdata=train,type="response")
predict2
table(train$happy,predict2>0.5)
table(train$happy,predict2>=0.5)
table(train$happy,predict2)
table(train$Happy,predict2>=0.5)
library(ROCR)
ROCRpred=prediction(predict2,train$Happy)
as.numeric(performance(ROCRpred,"auc")@y.values)
test=read.csv("test.csv")
predict2=predict(glm2,newdata=test,type="response")
submission = data.frame(UserID = test$UserID, Probability1 = predict2)
write.csv(submission, "submission.csv", row.names=FALSE)
glm3=glm(Happy~HouseholdStatus+Income+EducationLevel+Q122769+Q120194+Q120014+Q119334+Q119650+Q118237+Q115777+Q115611+Q115899+Q114386+Q113992+Q110740+Q107869+Q106388+Q106389+Q102674+Q102687+Q102289+Q102089+Q101162+Q100680+Q99716+Q98869,data=train,family=binomial)
train2=as.data.frame(cbind(train$Happy,train$HouseholdStatus,train$Income,train$EducationLevel,train$Q122769,train$Q120194,train$Q120014,train$Q119334,train$Q119650,train$Q118237,train$Q115777,train$Q115611,train$Q115899,train$Q114386,train$Q114386,train$Q113992,train$Q110740,train$Q107869,train$Q106388,train$Q106389,train$Q102687,train$Q102289,train$Q102089,train$Q101162,train$Q100680,train$Q99716,train$Q98869))
names(train2)
train2$V1[1]
class(train2)
nrow(train2)
library(caret)
library(e1071)
tr.control=trainControl(method="cv",number=10)
cp.grid=expand.grid(.cp=(0:10)*0.001)
tr=train(V1~.,data=train2,method="rpart",trControl=tr.control,tuneGrid=cp.grid)
best.tree=tr$finalModel
prp(best.tree)
library(rpart)
prp(best.tree)
library(rpart.plot)
prp(best.tree)
names(train)
CVpredict=predict(best.tree,newdata=test)
tr2=train(Happy~HouseholdStatus+Income+EducationLevel+Q122769+Q120194+Q120014+Q119334+Q119650+Q118237+Q115777+Q115611+Q115899+Q114386+Q113992+Q110740+Q107869+Q106388+Q106389+Q102674+Q102687+Q102289+Q102089+Q101162+Q100680+Q99716+Q98869,data=train,method="rpart",trControl=tr.control,tuneGrid=cp.grid)
best=tr2$finalModel
CARTpred=predict(best,newdata=test)
CARTpred=predict(best,newdata=train)
CARTpred=predict(best,newdata=train,type="class")
library(randomForest)
RF=randomforest(Happy~HouseholdStatus+Income+EducationLevel+Q122769+Q120194+Q120014+Q119334+Q119650+Q118237+Q115777+Q115611+Q115899+Q114386+Q113992+Q110740+Q107869+Q106388+Q106389+Q102674+Q102687+Q102289+Q102089+Q101162+Q100680+Q99716+Q98869,data=train,data=train,ntree=200,nodesize=25)
RF=randomForest(Happy~HouseholdStatus+Income+EducationLevel+Q122769+Q120194+Q120014+Q119334+Q119650+Q118237+Q115777+Q115611+Q115899+Q114386+Q113992+Q110740+Q107869+Q106388+Q106389+Q102674+Q102687+Q102289+Q102089+Q101162+Q100680+Q99716+Q98869,data=train,data=train,ntree=200,nodesize=25)
RF=randomForest(Happy~HouseholdStatus+Income+EducationLevel+Q122769+Q120194+Q120014+Q119334+Q119650+Q118237+Q115777+Q115611+Q115899+Q114386+Q113992+Q110740+Q107869+Q106388+Q106389+Q102674+Q102687+Q102289+Q102089+Q101162+Q100680+Q99716+Q98869,data=train,ntree=200,nodesize=25)
predictRF=predict(RF,newdata=test)
submission2 = data.frame(UserID = test$UserID, Probability1 = predictRF)
write.csv(submission2,"submission2.csv", row.names=FALSE)
distance=dist(train,method="euclidean")
cluster=hclust(distance,method="ward")
plot(cluster)
KMC=kmean(train,centers=4,iter.max=1000)
KMC=kmeans(train,centers=4,iter.max=1000)
str(KMC)
clustergroups=cutree(cluster,k=4)
clustergroupds
clustergroups
tapply(train$Happy,clusterGroups)
tapply(train$Happy,clustergroups,mean)
cluster1=subset(train,clustergroups==1)
cluster2=subset(train,clustergroups==2)
cluster3=subset(train,clustergroups==3)
cluster4=subset(train,clustergroups==4)
library(flexclust)
random2=randomForest(Happy~.,data=train,ntree=200,nodesize=25)
str(train)
summary(train)
is.na(train$Happy)
is.na(train)
train[is.na(train)]
train[is.na(train)]=0
train[is.na(train)]
train[is.na(train)]
a=0
a
train[is.na(train)]
is.na(train)
